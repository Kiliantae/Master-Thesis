{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropp 12 images from one image \n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"C:/Users/kbock/Desktop/Fracto/data/rawimg_zoom_10_20_100/zoom_100/0and1/\"\n",
    "image_path_split = \"C:/Users/kbock/Desktop/Fracto/data/rawimg_zoom_10_20_100/zoom_100/0and1_224_224(12)/\"\n",
    "\n",
    "for file in os.listdir(image_path):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        new_file = image_path + file        \n",
    "        img = Image.open(new_file) #1021_771 --> 340_385\n",
    "\n",
    "        #Bild laden, zerschneiden und Teile speichern\n",
    "        \n",
    "        imgCropped1 = img.crop((0,0,223,223)) #crop the image part (x_min,y_min,x_max,y_max) 224,224\n",
    "        imgCropped2 = img.crop((0,224,223,447)) #crop the image part\n",
    "        imgCropped3 = img.crop((0,448,223,671)) #crop the image part\n",
    "        imgCropped4 = img.crop((224,0,447,223)) #crop the image part\n",
    "        imgCropped5 = img.crop((224,224,447,447)) #crop the image part\n",
    "        imgCropped6 = img.crop((224,448,447,671)) #crop the image part\n",
    "        imgCropped7 = img.crop((448,0,671,223)) #crop the image part\n",
    "        imgCropped8 = img.crop((448,224,671,447)) #crop the image part\n",
    "        imgCropped9 = img.crop((448,448,671,671)) #crop the image part\n",
    "        imgCropped10 = img.crop((672,0,895,223)) #crop the image part\n",
    "        imgCropped11 = img.crop((672,224,895,447)) #crop the image part\n",
    "        imgCropped12 = img.crop((672,448,895,671)) #crop the image part\n",
    "        \"\"\"\n",
    "        imgCropped1 = img.crop((0,0,339,384)) #crop the image part (x_min,y_min,x_max,y_max) 340_385\n",
    "        imgCropped2 = img.crop((0,385,339,769)) #crop the image part\n",
    "        imgCropped3 = img.crop((340,0,679,384)) #crop the image part\n",
    "        imgCropped4 = img.crop((340,385,679,769)) #crop the image part\n",
    "        imgCropped5 = img.crop((680,0,1019,384)) #crop the image part\n",
    "        imgCropped6 = img.crop((680,385,1019,769)) #crop the image part\n",
    "        \"\"\"\n",
    "        \n",
    "        imgCropped1.save(image_path_split+\"1\"+file) \n",
    "        imgCropped2.save(image_path_split+\"2\"+file) \n",
    "        imgCropped3.save(image_path_split+\"3\"+file) \n",
    "        imgCropped4.save(image_path_split+\"4\"+file) \n",
    "        imgCropped5.save(image_path_split+\"5\"+file) \n",
    "        imgCropped6.save(image_path_split+\"6\"+file) \n",
    "        imgCropped1.save(image_path_split+\"7\"+file) \n",
    "        imgCropped2.save(image_path_split+\"8\"+file) \n",
    "        imgCropped3.save(image_path_split+\"9\"+file) \n",
    "        imgCropped4.save(image_path_split+\"10\"+file) \n",
    "        imgCropped5.save(image_path_split+\"11\"+file) \n",
    "        imgCropped6.save(image_path_split+\"12\"+file) \n",
    "      \n",
    "        \n",
    "        img.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table with 12 image informations instead of 1 \n",
    "import pandas as pd\n",
    "excel_path = \"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom100.xlsx\"\n",
    "excel_path_224_224 = \"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom100_224_224(12).xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "newdf = pd.DataFrame(data=[])\n",
    "for img_name in df[\"Fall-Nummer\"]:\n",
    "    for i in range(1,13):\n",
    "        df2 = df[df[\"Fall-Nummer\"]==img_name].drop(columns= [\"Fall-Nummer\"])\n",
    "        df2[\"Fall-Nummer\"] = str(i)+img_name\n",
    "        newdf = newdf.append(df2, ignore_index=True)\n",
    "        \n",
    "writer = pd.ExcelWriter(excel_path_224_224)\n",
    "newdf.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Materials = 'data/Materials_properties.xlsx'\n",
    "df = pd.read_excel(Materials)\n",
    "df = df.fillna(value=0).drop([\"Werkstoff-Name\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 32 nearest neighbors...\n",
      "[t-SNE] Indexed 33 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 33 samples in 0.003s...\n",
      "[t-SNE] Computed conditional probabilities for sample 33 / 33\n",
      "[t-SNE] Mean sigma: 4.157807\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 41.731464\n",
      "[t-SNE] KL divergence after 1000 iterations: -0.020853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "n = df.values\n",
    "n= n[:-1,:]\n",
    "tsne = TSNE(n_components=2, verbose=1,learning_rate=25, perplexity=20, n_iter=1000)\n",
    "X = tsne.fit_transform(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Material clusters')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.title(\"Material clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data/Materials_properties_clust.xlsx')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating excel table with all information (including kind of fracture and cluster)\n",
    "#from Materials_properties_clust.xlsx (consists of Materials and their cluster)\n",
    "import pandas as pd\n",
    "\n",
    "Materials_cluster_path = 'C:/Users/kbock/Desktop/Fracto/data/Materials_properties_clust.xlsx'\n",
    "excel_path ='C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom100_224_224(12).xlsx'\n",
    "excel_path_new ='C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom100_224_224(12)_clustered.xlsx'\n",
    "df = pd.read_excel(excel_path)\n",
    "df[\"Material_cluster\"] = None\n",
    "df_clus = pd.read_excel(Materials_cluster_path)\n",
    "newdf = pd.DataFrame(data=[])\n",
    "for img_name in df[\"Fall-Nummer\"]:\n",
    "    Werkstoff_Name=df.loc[df[\"Fall-Nummer\"]==img_name,[\"Werkstoff-Name\"]].values[0][0]\n",
    "\n",
    "    df.loc[df[\"Fall-Nummer\"]==img_name,[\"Material_cluster\"]]= df_clus.loc[df_clus[\"Werkstoff-Name\"]==Werkstoff_Name][\"Material_cluster\"].to_string()[5:]\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(excel_path_new)\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tansferlearning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Multiply\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "zoom_image_dir = \"C:/Users/kbock/Desktop/Fracto/data/rawimg_zoom_10_20_100/zoom_100/0and1_224_224(12)/\"\n",
    "excel_path = \"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom100_224_224(12)_clust.xlsx\"\n",
    "\n",
    "df = pd.read_excel(excel_path)#, engine='openpyxl')\n",
    "y =df[[\"Bruchart-id\"]]\n",
    "y = np.array(y)\n",
    "z =df[[\"Material_cluster\"]]\n",
    "z = np.array(z)\n",
    "X = 0\n",
    "for img_name in df[\"Fall-Nummer\"]:\n",
    "        image_path =zoom_image_dir + img_name + \".jpg\"\n",
    "        # load an image from file\n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = img_to_array(image) \n",
    "        # reshape data for the model\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        # prepare the image for the VGG model\n",
    "        image = preprocess_input(image)\n",
    "        try:\n",
    "            X = np.append(X,image,axis=0)\n",
    "        except Exception:\n",
    "            X = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.56 GiB for an array with shape (1524, 56, 56, 256) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ad0996802908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mX_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mX_mean_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_f\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1613\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m     \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fracto\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.56 GiB for an array with shape (1524, 56, 56, 256) and data type float32"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "model = VGG16()\n",
    "#model2 = Model(model.input, model.layers[-6].output) #conv5.3 mean  #bacc=0.763 #224_224 0,805 #340_385 0,83 # 0,83\n",
    "#model2 = Model(model.input, model.layers[-10].output) #conv4.3 mean  #bacc=0.678 # 0,866 #0,866 #0,85\n",
    "model2 = Model(model.input, model.layers[-14].output) #conv3.3 mean #bacc ##0,882 #0,84\n",
    "#model2 = Model(model.input, model.layers[-18].output) #conv2.2 mean  #bacc=0.636 ###0,8\n",
    "#model2 = Model(model.input, model.layers[-21].output) #conv1.2 mean  #bacc=0.593\n",
    "model2.summary()\n",
    "\n",
    "X_f = model2.predict(X)\n",
    "X_mean_f = np.mean(X_f,axis=(1,2)) #mean\n",
    "#X_max_f = np.amax(X_f,axis=(1,2)) #max\n",
    "#import tensorflow as tf\n",
    "#def gram_matrix(input_tensor):\n",
    "#    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "#    input_shape = tf.shape(input_tensor)\n",
    "#    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
    "#    return result/(num_locations)\n",
    "#X_gram_f = np.reshape(gram_matrix(X_f),[len(y),-1]) #gram matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "from skimage import io, color, img_as_ubyte\n",
    "import mahotas as mt\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints, #lbp image\n",
    "            self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist, lbp\n",
    "    \n",
    "def LBP(image_dir_or_path, image_dir_lbp=None):\n",
    "    desc= LocalBinaryPatterns(24,3)\n",
    "    #for file in os.listdir(image_dir):\n",
    "    #img = cv2.imread(image_dir+\"/\"+file,cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.imread(image_dir_or_path,cv2.IMREAD_GRAYSCALE)\n",
    "    hist, img_lbp = desc.describe(image=img)\n",
    "        #img_lbp = Image.fromarray(img_lbp, 'L')\n",
    "        #img_lbp.save(image_dir_lbp+\"/\"+file)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "table_dir=\"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/\"\n",
    "image_dir= \"C:/Users/kbock/Desktop/Fracto/data/rawimg_zoom_10_20_100/\"\n",
    "extracted_features_dir= \"C:/Users/kbock/Desktop/Fracto/data/extracted_features_zoom_10_20_100/\"\n",
    "zoom =[10,20,100]\n",
    "for z in zoom:\n",
    "    zoom_table_path = os.path.join(table_dir +\"Raw_data_zoom{}_224_224(12)_clust.xlsx\".format(z))\n",
    "    zoom_image_dir = image_dir + \"zoom_{}/\".format(z) + \"0and1_224_224(12)/\"\n",
    "    df = pd.read_excel(zoom_table_path)#, engine='openpyxl')\n",
    "    train_features = []\n",
    "\n",
    "    for img_name in df[\"Fall-Nummer\"]:\n",
    "        image_path =zoom_image_dir + img_name + \".jpg\"\n",
    "        #calculate features\n",
    "        features = LBP(image_path)\n",
    "        # append the feature vector and label\n",
    "        train_features.append(features)\n",
    "\n",
    "    scaler = StandardScaler() \n",
    "    train_features= np.asarray(train_features)\n",
    "    train_features = scaler.fit_transform(train_features)   \n",
    "    table = pd.DataFrame(data=train_features)      \n",
    "    table.to_csv(index=False, path_or_buf = extracted_features_dir+ \"{}zoom_224_224(12)_clust/\".format(z)+'{}zoom_LBP_hist.csv'.format(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLCM with haralick features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "from skimage import io, color, img_as_ubyte\n",
    "import mahotas as mt\n",
    "\n",
    "        \n",
    "\n",
    "def extract_haralick_features_from_glcm(image_path):\n",
    "        #calculate haralick texture features for 4 types of adjacency (glcm)\n",
    "        img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        #convert the image to grayscale\n",
    "        #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        textures = mt.features.haralick(img)\n",
    "        # take the mean and max of it and return it\n",
    "        ht_mean = textures.mean(axis=0)\n",
    "        ht_range = textures.max(axis=0) -textures.min(axis=0)\n",
    "        ht = np.concatenate((ht_mean,ht_range),axis =None)\n",
    "        return ht\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "table_dir=\"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/\"\n",
    "image_dir= \"C:/Users/kbock/Desktop/Fracto/data/rawimg_zoom_10_20_100/\"\n",
    "extracted_features_dir= \"C:/Users/kbock/Desktop/Fracto/data/extracted_features_zoom_10_20_100/\"\n",
    "zoom =[10,20,100]\n",
    "for z in zoom:\n",
    "    zoom_table_path = os.path.join(table_dir +\"Raw_data_zoom{}_224_224(12)_clust.xlsx\".format(z))\n",
    "    zoom_image_dir = image_dir + \"zoom_{}/\".format(z) + \"0and1_224_224(12)/\"\n",
    "    df = pd.read_excel(zoom_table_path)#, engine='openpyxl')\n",
    "    train_features = []\n",
    "\n",
    "    for img_name in df[\"Fall-Nummer\"]:\n",
    "        image_path =zoom_image_dir + img_name + \".jpg\"\n",
    "        #calculate features\n",
    "        features = extract_haralick_features_from_glcm(image_path)\n",
    "        # append the feature vector and label\n",
    "        train_features.append(features)\n",
    "\n",
    "    scaler = StandardScaler() \n",
    "    train_features= np.asarray(train_features)\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    \n",
    "    table = pd.DataFrame(data=train_features)      \n",
    "    #writer = pd.ExcelWriter(extracted_features_dir+ \"{}zoom_224_224(12)_clust/\".format(z)+'{a}zoom_GLCMharalickmeanandrang.xlsx'.format(a=z))\n",
    "    #table.to_excel(writer)\n",
    "    #writer.save()\n",
    "    table.to_csv(index=False, path_or_buf = extracted_features_dir+ \"{}zoom_224_224(12)_clust/\".format(z)+'{}zoom_GLCMharalickmeanandrang.csv'.format(z)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X_mean_f = scaler.fit_transform(X_mean_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= 20\n",
    "excel_path = \"C:/Users/kbock/Desktop/Fracto/data/raw_zoom_10_20_100/Raw_data_zoom{}_224_224(12)_clust.xlsx\".format(p)\n",
    "df = pd.read_excel(excel_path)#, engine='openpyxl')\n",
    "#y =df[[\"Bruchart-id\"]]\n",
    "#z =df[[\"Material_cluster\"]]\n",
    "path= \"C:/Users/kbock/Desktop/Fracto/data/extracted_features_zoom_10_20_100/\" + \"{}zoom_224_224(12)_clust/\".format(p) +'{}zoom_LBP_hist.csv'.format(p)\n",
    "table = pd.read_csv(path)\n",
    "#save image features in csv file\n",
    "#table = pd.DataFrame(data=X_mean_f)  \n",
    "df_new = pd.concat([df[[\"Bruchart-id\"]],df[[\"Material_cluster\"]],table], axis=1)\n",
    "\n",
    "df_new.to_csv(index=False, path_or_buf =\"C:/Users/kbock/Desktop/Fracto/data/extracted_features_zoom_10_20_100/\"+ \"{}zoom_224_224(12)_clust/\".format(p)+'{}zoom_LBP_hist.csv'.format(p)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = MLPClassifier( alpha=1e-5, random_state=1,max_iter=100,solver=\"sgd\")\n",
    "#model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, max_iter=10000, random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################\n",
      "endtime-starttime:  14.352745056152344\n",
      "100zoom_VGG16_conv33_mean_standardized.csv\n",
      "bacc = 0.84\n",
      "f1 = 0.8\n",
      "bacc_cluster = 0.76\n",
      "f1_cluster macro = 0.66\n",
      "f1_cluster weighted = 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kbock\\Anaconda3\\envs\\fracto\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "magnify= [100]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "kf = KFold(n_splits=6, random_state=0, shuffle=True)\n",
    "#data = [\"zoom_VGG16_conv33_mean_standardized.csv\"]\n",
    "data= [\"zoom_VGG16_conv33_mean_standardized.csv\"]\n",
    "[#\"zoom_LBP_hist.csv\",\n",
    "       #\"zoom_GLCMharalickmeanandrang.csv\" ,\n",
    "       #\"zoom_VGG16_conv33_mean_standardized.csv\",\n",
    "       #\"zoom_VGG16_conv43_mean_standardized.csv\",\n",
    "       #\"zoom_VGG16_conv53_mean_standardized.csv\"\n",
    "      ]\n",
    "for p in magnify:\n",
    "    for d in data:\n",
    "        df = pd.read_csv(\"C:/Users/kbock/Desktop/Arbeitsordner/data/processed_data/\"+ \"{}zoom_224_224(12)_clust/\".format(p)+'{}{}'.format(p,d))\n",
    "        y =df[[\"Bruchart-id\"]]\n",
    "        y = np.array(y)\n",
    "        z =df[[\"Material_cluster\"]]\n",
    "        z = np.array(z)\n",
    "        X = df.drop([\"Bruchart-id\",\"Material_cluster\"], axis=1).to_numpy()\n",
    "\n",
    "        bacc = []\n",
    "        bacc_cluster = []\n",
    "        f1 = []\n",
    "        f1_cluster_macro = []\n",
    "        f1_cluster_weighted = []\n",
    "        starttime = time.time()\n",
    "        X_split = np.arange(len(X)/12)\n",
    "        for train_index, test_index in kf.split(X_split):\n",
    "            train_index = np.multiply(train_index,12)\n",
    "            app= []\n",
    "            for t in train_index:\n",
    "                app.append(t+1)\n",
    "                app.append(t+2)\n",
    "                app.append(t+3)\n",
    "                app.append(t+4)\n",
    "                app.append(t+5)\n",
    "                app.append(t+6)\n",
    "                app.append(t+7)\n",
    "                app.append(t+8)\n",
    "                app.append(t+9)\n",
    "                app.append(t+10)\n",
    "                app.append(t+11)\n",
    "            train_index = np.append(train_index,app)\n",
    "            test_index = np.multiply(test_index,12)\n",
    "            app= []\n",
    "            for t in test_index:\n",
    "                app.append(t+1)\n",
    "                app.append(t+2)\n",
    "                app.append(t+3)\n",
    "                app.append(t+4)\n",
    "                app.append(t+5)\n",
    "                app.append(t+6)\n",
    "                app.append(t+7)\n",
    "                app.append(t+8)\n",
    "                app.append(t+9)\n",
    "                app.append(t+10)\n",
    "                app.append(t+11)\n",
    "            test_index = np.append(test_index,app)\n",
    "            \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            z_train, z_test = z[train_index], z[test_index]\n",
    "            y_train = np.ravel(y_train)\n",
    "            z_train = np.ravel(z_train)\n",
    "            y_test = np.ravel(y_test)\n",
    "            z_test = np.ravel(z_test)\n",
    "\n",
    "            model.fit(X_train, y_train)#, sample_weight=None)\n",
    "            ypred = model.predict(X_test)\n",
    "            bacc.append(balanced_accuracy_score(y_test,ypred))\n",
    "            f1.append(f1_score(y_test,ypred))\n",
    "\n",
    "            model.fit(X_train, z_train)#, sample_weight=None)\n",
    "            zpred = model.predict(X_test)\n",
    "            bacc_cluster.append(balanced_accuracy_score(z_test,zpred))\n",
    "            f1_cluster_macro.append(f1_score(z_test,zpred,average='macro'))\n",
    "            f1_cluster_weighted.append(f1_score(z_test,zpred,average='weighted'))\n",
    "            \n",
    "        endtime = time.time()\n",
    "        print(\"############################\")\n",
    "        print(\"endtime-starttime: \", endtime-starttime)\n",
    "        print(\"{}{}\".format(p,d))\n",
    "        print(\"bacc =\", round(Average(bacc), 2))\n",
    "        print(\"f1 =\", round(Average(f1), 2))\n",
    "        print(\"bacc_cluster =\", round(Average(bacc_cluster), 2))\n",
    "        print(\"f1_cluster macro =\", round(Average(f1_cluster_macro), 2))\n",
    "        print(\"f1_cluster weighted =\", round(Average(f1_cluster_weighted), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
